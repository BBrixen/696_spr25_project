OpenAI GPT-3 Waiting List Dropped as GPT-3 Is Fully Released for Developer and Enterprise Use Home About AIwire Subscribe Events Contacts RSS Feeds Covering Scientific & Technical AI | Wednesday, April 30, 2025 Menu HOME FEATURES Articles Happening Now AI Executive Videos COVID SYSTEMS SILICON SOFTWARE STORAGE NETWORKS DATACENTER EDGE/IOT SECURITY SECTORS Financial Services Government Healthcare Life Sciences Energy Manufacturing Retail Media Academia Follow AIwire: OpenAI GPT-3 Waiting List Dropped as GPT-3 Is Fully Released for Developer and Enterprise Use November 18, 2021 by Todd R. Weiss When OpenAI first debuted its powerful GPT-3 natural language model in June of 2020, it debuted in a limited beta capacity and featured a waiting list where developers could sign up to use its infrastructure and capabilities. Now, the waiting list has been dropped and GPT-3’s capabilities are immediately available to developers and enterprises to work on their most challenging language problems, according to a Nov. 18 (Thursday) announcement by OpenAI, an independent AI research and deployment company. But there are some caveats – the general release adds conditions to prevent GPT-3 from being used to harm people, as well as conditions that only allow its use in certain nations around the world. That means that developers in some nations, including Cuba, Iran and Russia, cannot currently access it. “OpenAI is committed to the safe deployment of AI,” the organization said in a statement. “Since the launch of our API, we’ve made deploying applications faster and more streamlined while adding new safety features. Our progress with safeguards makes it possible to remove the waitlist for GPT-3. Starting today, developers in supported countries can sign up and start experimenting with our API right away.” By having the safeguards to protect people and prohibit developers in certain nations from using the API, OpenAI was to forgo the wait list, the group said. “As our safeguards continue to improve, we will expand how the API can be used while further improving the experience for our users.” GPT-3 is a massive natural language model that runs exclusively on Microsoft Azure. GPT-3, which stands for Generative Pre-trained Transformer 3, is an autoregressive language model with 175 billion parameters , which OpenAI claims is ten times more than any previous non-sparse language model. The first version, GPT-1, was released in 2018, while the second version, GPT-2, debuted in 2019. With the release of GPT-3 in 2020, natural language processing (NLP) gained more power and use cases in the enterprise than ever before. The latest OpenAI API , which includes GPT-3 and is now readily available, contains a host of safety improvements, including Instruct Series models that adhere better to human instructions, specialized endpoints for more truthful question-answering , and a free content filter to help developers mitigate accidental abuse. In addition, the latest OpenAI includes monitoring capabilities that allow the organization to review applications that incorporate GPT-3 before they go live and monitor those applications for misuse of the API and code to protect humanity and better understand the effects of the technology, the group said in its announcement. “To ensure API-backed applications are built responsibly, we provide tools and help developers use best practices so they can bring their applications to production quickly and safely,” the group said. “As our systems evolve and we work to improve the capabilities of our safeguards, we expect to continue streamlining the process for developers, refining our Usage Guidelines , and allowing even more use cases over time.” As part of the full release of the API, OpenAI is also updating its Content Guidelines to clarify what kind of content the API can be used to generate. The guidelines prohibit content that features hate, harassment, violence, self-harm, adult sexual situations, politics, spam, deception or malware. “We also work with researchers who are looking to use the API for research or building use-cases to address related harms,” the group says. “Our policies have always prohibited the use of our API in ways that do not adhere to the principles described in our charter , and content like hate speech remains prohibited,” the announcement states. “We are also prohibiting certain types of content on our API, like adult content, where our system is not currently able to reliably discern harmful from acceptable use. We are continually working to make our content filters more robust, and we intend to allow acceptable use within some categories as our system improves.” Other changes in the latest OpenAI API include an improved Playground, which makes it easy to prototype with the group’s models, an example library with dozens of prompts to get developers started, and Codex , a new model that translates natural language into code. The API has been used in thousands of applications with tasks ranging from helping people learn new languages to solving complex classification problems. Peter Welinder of OpenAI Peter Welinder , the vice president of product and partnerships for OpenAI told EnterpriseAI that so far GPT-3 is primarily for English modeling. “We have found that it is also adept at translation, for example, from English to French.” The API full release is a milestone for the organization, said Welinder. “We wanted to release our technology in a safe and responsible way ... so we, in turn, can learn how our technology can be used. We have worked hard to improve our API and safety features over this time and are excited to make it more widely available. Today’s announcement is a significant step towards our commitment to safety and we hope to inspire our industry peers.” Analysts on the OpenAI Moves James Kobielus, analyst James Kobielus , the senior research director for data communications and management at TDWI, a data analytics consultancy, told EnterpriseAI that OpenAI’s approach to the full release of its API and GPT-3 is a good one. “This is an impressively comprehensive support for responsible AI for developers eager to deploy GPT-3-generated large language models into conversational AI, algorithmic news writing and other applications,” said Kobielus. At the same time, he said, when looking over the list of countries where the use of the API is permitted, he noted that “there are several known sponsors of state-based terrorism that are excluded.” There is no explanation for how the countries are chosen or left out, though, and that raises some concerns, he said. “I am wondering what OpenAI’s criteria are for including or excluding countries from this list, whether this constitutes as a ‘blacklisting’ approach, and who ultimately decides to include a country that is currently excluded or exclude a country that is currently on the list if developers in that country happen to start abusing the API with active or tacit support from those governments,” said Kobielus. “On the whole, I applaud OpenAI’s comprehensive focus on weeding out abuses of its GPT-3 technology related to generating hateful or violence-encouraging ‘toxic’ language … as well as spam, malware, deception and algorithmic political manipulation.” Problems could be possible when it comes to the prohibitions on “content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education and wellness),” which seems a bit overbroad, said Kobielus. “Think of all the socially-redeeming literary uses of GPT-3 that might run afoul of this prohibition. Recall that James Joyce’s ‘Ulysses,’ D.H. Lawrence’s ‘Lady Chatterley’s Lover,’ and other works now deemed classics were banned in places a century ago due to their depiction of activities that might fit that description. Let us not give today’s censors the ability to cite restrictions such as this from restricting the algorithmic generation of great art going forward.” Rob Enderle, analyst Another analyst, Rob Enderle , principal of Enderle Group, said he also has some concerns with the use of AI when it comes to public safety, so he is happy to see OpenAI taking some responsibility with these matters. “AI has the potential to both change society for the better and wipe it out [if unchecked],” said Enderle. “Were it to go rogue or be used for hostile intent, it could do damage at a rate that humans could not possibly counter once the [rogue behaviors] mature. Therefore, ensuring a positive outcome is one of the most critical things we can do as a race to avoid the related existential threat. OpenAI recognizes the threat, and this announcement showcases both their focus on eliminating it and their ability to scale the protections, so they do not hamper positive AI development.” This approach contrasts AI development being done by other organizations, said Enderle. “Sadly, not all AI development is being done as safely, suggesting that one of the other things OpenAI should be focused on is creating defensive AIs that can be used if someone else’s AI development goes rogue,” he explained. “Until such protections are in place, the risk of an AI becoming an active existential threat remains very real.” Bill Weinberg , an open source strategist with Linux Pundit, said the decision to end the beta for the API and release it to developers in general is the right choice. Bill Weinberg, analyst “To paraphrase [the writer and creator of “The Whole Earth Catalog”] Stewart Brand and Steve Wozniak, APIs also want to be free,” said Weinberg. “The move to remove the wait list to access to the OpenAI API set is a huge step in the right direction, benefitting developers, researchers, and as the founders of OpenAI insist, benefiting humanity as well. Removing the waiting list is also a great sign of OpenAI’s confidence in the model and in its ability to compete in an increasingly dynamic AI marketplace.” Weinberg also said he disagrees with OpenAI’s contention that the group’s GPT-3 implementation is open source. Yes, it is community-facing, he said, but “it is definitely not open source, open APIs notwithstanding. OpenAI broke from its launch-time commitment to open source in 2019 over concerns of perpetuating fake news and when the organization shifted to for-profit status. Moreover, the API Content Guidelines, while laudable in their intent – prohibiting applications for hate, harassment, violence, etc. – most definitely would not pass OSI muster for freedom of use.” GPT-3 has been steadily gaining more interest in the world of enterprise IT over the last several years. Microsoft exclusively licensed GPT-3 from OpenAI in September 2020, extending an existing relationship between the two companies. The licensing agreement covers the use of GPT-3 for all Microsoft products and services. In May, Microsoft announced the first such integration of GPT-3 into one of its products, its Microsoft Power Apps software , which aims to make it easier for enterprise workers to build no-code and low-code applications. The Microsoft licensing deal was not an exclusive arrangement. Others can still use the GPT-3 model through OpenAI’s API, according to OpenAI. In May, OpenAI launched a $100 million AI startup fund to provide investment money to startups that are driving intriguing AI technologies. The fund is slated to help a few early-stage startups in fields where artificial intelligence can have a transformative effect, including healthcare, climate change, education and in areas where AI tools can empower people by helping them be more productive using personal assistants and semantic search, the company said. A wide range of enterprises are developing with GPT-3 today, including Disney, IBM, Twitter, Salesforce, Cisco and Intel, according to OpenAI. Related Categories: AI/ML/DL Tags: AI , artificial intelligence , GPT-3 , Machine Learning , ML , natural language models , natural language processing , OpenAI Happening Now Tuesday, April 29 Writer Launches Palmyra X5 with 1M Token Context and Enterprise-Grade Efficiency Argonne Examines Opportunities and Risks of GenAI Tools GigaIO Demonstrates Power and Cost Savings with New AI Interconnect Benchmarks RWS TrainAI Study Finds Claude Sonnet, GPT and Gemini Pro Lead in Synthetic Data Generation Monday, April 28 NCSA’s CAII Receives NASA Funding to Assist Euclid Space Mission Oracle Expands OCI with 1st Wave of NVIDIA Blackwell GB200 Systems Game Changer London 2025 to Spotlight AI, Cybersecurity, and Digital Innovation, May 8 Friday, April 25 NSF Director Announces Immediate Resignation GigaIO Announces General Availability for Gryf to Enable Field-Based AI Processing Thursday, April 24 Jülich Welcomes EU Executive VP to Preview JUPITER AI Factory ACM Names Cordelia Schmid 2025 Athena Lecturer for Work in Computer Vision Wednesday, April 23 Fujitsu Expands Strategic Collaboration with Supermicro to Offer Total Generative AI Platform CNCF Announces OpenObservabilityCon North America Tuesday, April 22 Argonne Leverages AI and Supercomputing to Advance Cancer Research SandboxAQ Tackles AI Agent Cyber Threats with New AQtive Guard Platform Monday, April 21 MIT: Making AI-Generated Code More Accurate in Any Language Cadence Introduces Industry-First DDR5 12.8Gbps MRDIMM Gen2 IP on TSMC N3 for Cloud AI Friday, April 18 EPAM Report Highlights Disconnect Between AI Ambitions and Deployment RISA Labs Raises $3.5M for AI-Powered Workflow Automation in Oncology Cadence Releases 12.8Gbps HBM4 IP for AI and HPC System Designers More Happening Now Tabor Network Recent News Parallel Works Unveils ACTIVATE High Security Platform, Secures Key DoD Accreditation April 29, 2025 It’s Time to Get Comfortable with Uncertainty in AI Model Training April 28, 2025 Nature Reports a US Science Brain Drain Has Begun April 25, 2025 Lenovo Storage Portfolio Refresh Aims to Speed Up AI Inference April 23, 2025 Claude’s Moral Map: Anthropic Tests AI Alignment in the Wild April 21, 2025 Contributors Tiffany Trader Editorial Director Jaime Hampton Managing Editor Kevin Jackson Contributing Editor John Russell Contributing Editor Alex Woodie Contributing Editor Douglas Eadline Contributing Editor Ali Azhar Contributing Editor Drew Jolly Assistant Editor © 2025 AIwire. All Rights Reserved. A Tabor Communications Publication About AIwire Contacts Privacy Policy Cookie Policy Back to Top Update Subscription Preferences California Consumers AIwire This website uses cookies to improve your experience. We'll assume you're ok with this, but you can opt-out if you wish. Accept Read More Privacy & Cookies Policy Close Privacy Overview This website uses cookies to improve your experience while you navigate through the website. Out of these, the cookies that are categorized as necessary are stored on your browser as they are essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may affect your browsing experience. Necessary Necessary Always Enabled Necessary cookies are absolutely essential for the website to function properly. This category only includes cookies that ensures basic functionalities and security features of the website. These cookies do not store any personal information. Non-necessary Non-necessary Any cookies that may not be particularly necessary for the website to function and is used specifically to collect user personal data via analytics, ads, other embedded contents are termed as non-necessary cookies. It is mandatory to procure user consent prior to running these cookies on your website. SAVE & ACCEPT Share Blogger Bluesky Delicious Digg Email Facebook Facebook messenger Flipboard Google Hacker News Line LinkedIn Mastodon Mix Odnoklassniki PDF Pinterest Pocket Print Reddit Renren Short link SMS Skype Telegram Tumblr Twitter VKontakte wechat Weibo WhatsApp X Xing Yahoo! Mail Copy short link Copy link