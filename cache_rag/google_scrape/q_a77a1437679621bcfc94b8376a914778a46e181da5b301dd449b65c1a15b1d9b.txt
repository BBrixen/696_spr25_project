GPT-3: What’s it good for? | Natural Language Engineering | Cambridge Core Skip to main content Accessibility help We use cookies to distinguish you from other users and to provide you with a better experience on our websites. Close this message to accept cookies or find out how to manage your cookie settings . Login Alert Cancel Log in × × Discover Content Products and Services Register Log In (0) Cart Logo for Cambridge Core from Cambridge University Press. Click to return to homepage. Search Logo for Cambridge Core from Cambridge University Press. Click to return to homepage. Browse Services Open research Institution Login Search Menu links Browse Subjects Subjects (A-D) Anthropology Archaeology Area Studies Art Chemistry Classical Studies Computer Science Drama, Theatre, Performance Studies Subjects (E-K) Earth and Environmental Science Economics Education Engineering English Language Teaching – Resources for Teachers Film, Media, Mass Communication General Science Geography History Subjects (L-O) Language and Linguistics Law Life Sciences Literature Management Materials Science Mathematics Medicine Music Nutrition Subjects (P-Z) Philosophy Physics and Astronomy Politics and International Relations Psychiatry Psychology Religion Social Science Research Methods Sociology Statistics and Probability Open access All open access publishing Open access Open access journals Research open journals Journals containing open access Open access articles Open access books Open access Elements Journals Explore All journal subjects Search journals Open access Open access journals Research open journals Journals containing open access Open access articles Collections Cambridge Forum Cambridge Law Reports Collection Cambridge Prisms Research Directions Books Explore Books Open access books New books Flip it Open Collections Cambridge Companions Cambridge Editions Cambridge Histories Cambridge Library Collection Cambridge Shakespeare Cambridge Handbooks Collections (cont.) Dispute Settlement Reports Online Flip it Open Hemingway Letters Shakespeare Survey Stahl Online The Correspondence of Isaac Newton Elements Explore About Elements Elements series Open access Elements New Elements Subjects (A-E) Anthropology Archaeology Classical Studies Computer Science Drama, Theatre, Performance Studies Earth and Environmental Sciences Economics Education Engineering Subjects (F-O) Film, Media, Mass Communication History Language and Linguistics Law Life Sciences Literature Management Mathematics Medicine Music Subjects (P-Z) Philosophy Physics and Astronomy Politics and International Relations Psychology Religion Sociology Statistics and Probability Textbooks Explore Cambridge Higher Education Title list New titles Collections Book collections Cambridge Companions Cambridge Editions Cambridge Histories Cambridge Library Collection Cambridge Shakespeare Cambridge Handbooks Book collections (cont.) Dispute Settlement Reports Online Flip it Open Hemingway Letters Shakespeare Survey Stahl Online The Correspondence of Isaac Newton Journal collections Cambridge Forum Cambridge Law Reports Collection Cambridge Prisms Research Directions Series All series Partners Partners Agenda Publishing Amsterdam University Press Anthem Press Boydell & Brewer Bristol University Press Edinburgh University Press Emirates Center for Strategic Studies and Research Facet Publishing Partners (cont.) Foundation Books Intersentia ISEAS-Yusof Ishak Institute Jagiellonian University Press Royal Economic Society Unisa Press The University of Adelaide Press Wits University Press Services About About Cambridge Core About Accessibility CrossMark policy Ethical Standards Environment and sustainability Environment and sustainability Reducing print Journals moving to online only Guides User guides User Guides and Videos Support Videos Training Help Cambridge Core help Contact us Technical support Agents Services for agents Services for agents Journals for agents Books for agents Price list Authors Journals Journals Journal publishing statistics Corresponding author Seeking permission to use copyrighted material Publishing supplementary material Writing an effective abstract Journal production - FAQs Journals (cont.) Author affiliations Co-reviewing policy Anonymising your manuscript Publishing open access Converting your article to open access Publishing Open Access - webinars Journals (cont.) Preparing and submitting your paper Publication journey Publishing agreement FAQs for journal authors Author Information Form FAQs Promoting your published paper Measuring impact Journals artwork guide Using ORCID Books Books Marketing your book Author guides for Cambridge Elements Corporates Corporates Commercial reprints Advertising Sponsorship Book special sales Contact us Editors Information Journal development Peer review for editors Open access for editors Policies and guidelines Resources The editor's role Open research for editors Engagement and promotion Blogging Social media Librarians Information Open Access for Librarians Transformative agreements Transformative Agreements - FAQs Evidence based acquisition ebook news & updates Cambridge libraries of the world podcast Purchasing models Journals Publishing Updates Products Cambridge frontlist Cambridge journals digital archive Hot topics Other digital products Perpetual access products Price list Developing country programme New content Tools Eligibility checker Transformative agreements KBART MARC records Using MARCEdit for MARC records Inbound OpenURL specifications COUNTER usage reporting Resources Catalogues and resources Making the most of your EBA Posters Leaflets and brochures Additional resources Find my sales contact Webinars Read and publish resources Peer review Peer review How to peer review journal articles How to peer review book proposals How to peer review Registered Reports Peer review FAQs Ethics in peer review Online peer review systems A guide to Publons Publishing ethics Journals Publishing ethics guidelines for journals Core editorial policies for journals Authorship and contributorship for journals Affiliations for journals Research ethics for journals Competing interests and funding for journals Journals (cont.) Data and supporting evidence for journals Misconduct for journals Corrections, retractions and removals for journals Versions and adaptations for journals Libel, defamation and freedom of expression Business ethics journals Books Publishing ethics guidelines for books Core editorial policies for books Authorship and contributorship for books Affiliations for books Research ethics for books Competing interests and funding for books Books (cont.) Data and supporting evidence for books Misconduct for books Corrections, retractions and removals for books Versions and adaptations for books Libel, defamation and freedom of expression Business ethics books Publishing partners Publishing partners Publishing partnerships Partner books eBook publishing partnerships Journal publishing partnerships Publishing partners (cont.) Journals publishing Customer support Membership Services Our Team Open research Open access policies Open access policies Open research Open access policies Cambridge University Press and Plan S Text and data mining Preprint policy Social sharing Journals Open access journals Gold Open Access journals Transformative journals Green Open Access policy for journals Transparent pricing policy for journals Books and Elements Open access books Gold open access books Green Open Access policy for books Open access Elements Open access publishing About open access Open research Open Access Week What is open access? Open access glossary Open access myths Hybrid Open Access FAQs Eligibility checker Open access resources Open access resources Benefits of open access Creative commons licences Funder policies and mandates Article type definitions Convert your article to Open Access Open access video resources Open research initiatives Research transparency Transparency and openness Open Practice Badges OA organisations, initiatives & directories Registered Reports Annotation for Transparent Inquiry (ATI) Journal flips Open access journal flips OA Journal Flip FAQs Flip it Open Flip it Open Flip it Open FAQs Open access funding Open access funding Funding open access publication Cambridge Open Equity Initiative Completing a RightsLink (open access) transaction Cambridge Open Engage Cambridge Open Engage Cambridge Open Engage Partner With Us Branded Hubs Event Workspaces Partner Resources APSA Preprints APSA Preprints FAQs Hostname: page-component-669899f699-7xsfk     Total loading time: 0     Render date: 2025-04-29T06:43:26.375Z     Has data issue: false     hasContentIssue false Home > Journals > Natural Language Engineering > Volume 27 Issue 1 > GPT-3: What’s it good for? English Français Natural Language Engineering Article contents Abstract Introduction Some history GPT-3: A generator to trump all others Can you trust a transformer? Unreliable doesn’t mean useless Should we be worried after all? References GPT-3: What’s it good for? Published online by Cambridge University Press: 15 December 2020 Robert Dale Show author details Robert Dale* Affiliation: Language Technology Group Article Metrics Article contents Abstract Introduction Some history GPT-3: A generator to trump all others Can you trust a transformer? Unreliable doesn’t mean useless Should we be worried after all? References Save PDF Save PDF (0.14 mb) View PDF [Opens in a new window] Save to Dropbox Save to Google Drive Save to Kindle Share Cite Rights & Permissions [Opens in a new window] Abstract GPT-3 made the mainstream media headlines this year, generating far more interest than we’d normally expect of a technical advance in NLP. People are fascinated by its ability to produce apparently novel text that reads as if it was written by a human. But what kind of practical applications can we expect to see, and can they be trusted? Type Industry Watch Information Natural Language Engineering , Volume 27 , Issue 1 , January 2021 , pp. 113 - 118 DOI: https://doi.org/10.1017/S1351324920000601 [Opens in a new window] Creative Commons This is an Open Access article, distributed under the terms of the Creative Commons Attribution licence ( http://creativecommons.org/licenses/by/4.0/ ), which permits unrestricted re-use, distribution, and reproduction in any medium, provided the original work is properly cited. Copyright © Cambridge University Press 2020 1. Introduction The mid-year release of OpenAI’s GPT-3 language model, with its ability to generate natural language texts that can be remarkably hard to distinguish from human-authored content, was this year’s big AI news item. It received coverage in both the technical and mainstream media far in excess of what you’d normally expect for a technical advance in NLP. Here’s a sample of headlines from the tech industry press: • ZDNet , 1st June: ‘OpenAI’s gigantic GPT-3 hints at the limits of language models for AI’ Footnote a • MIT Technology Review , 20th July: ‘OpenAI’s new language generator GPT-3 is shockingly good – and completely mindless’ Footnote b • Wired , 22nd July: ‘Did a person write this headline, or a machine? GPT-3, a new text-generating program from OpenAI, shows how far the field has come – and how far it has to go’ Footnote c • The Verge , 30th July: ‘OpenAI’s latest breakthrough is astonishingly powerful but still fighting its flaws’ Footnote d Reading just the titles gives an accurate flavour of the tone of this coverage: an acknowledgement of just how impressive the technology is, but tempered with a recognition of its limitations. At least on the basis of the headlines, coverage in the mainstream media was a little more alarmist, expressing both awe and anxiety in response to GPT-3’s capabilities: • BBC News , 24th July: ‘Have we seen our future?’ Footnote e • The New York Times, 29th July: ‘How do you know a human wrote this? Machines are gaining the ability to write, and they are getting terrifyingly good at it’ Footnote f • The Economist , 6th August: ‘A new AI language model generates poetry and prose: GPT-3 can be eerily human-like – for better and for worse’ Footnote g • The UK’s Telegraph , 26th August: ‘Forget deepfakes – we should be very worried about AI-generated text’ Footnote h Headlines that hint at the overtaking of the human race by smart machines make for good clickbait, but if you read any of these articles, you’ll see that they are generally less sensationalist than their titles might suggest, and in fact they usually reflect quite well the limitations of the technology that have been commented upon in the more technical press. Regardless, in terms of the column inches devoted to it, the release of GPT-3 has clearly been the most significant AI news event of the year. But once you get past the ‘wow’ factor, what’s this technology actually good for? What kinds of commercial applications might we expect to see? And are there applications we should discourage? 2. Some history First, let’s review how we got here. OpenAI was founded as a non-profit research organisation in late 2015 via a collective pledge of US$1B from a group of industry heavyweights, including Sam Altman (Y Combinator), Greg Brockman (Stripe), Reid Hoffman (LinkedIn), Elon Musk (Tesla) and Peter Thiel (Palantir). Its mission is to ensure that artificial general intelligence (AGI) benefits all of humanity; and in line with that mission, the goal of being the first to develop AGI. Over its first few years, the organisation publicly released a number of software artefacts, but nothing that made headlines outside of the relevant communities of interest. Then, in February 2019, OpenAI announced GPT-2 (for Generative Pre-trained Transformer 2), a large unsupervised transformer language model with 1.5B parameters trained on 40GB of text, or roughly 10B tokens. When used to repeatedly predict the next word in a text based on the preceding context, the model was capable of generating very coherent and plausible-sounding output, although it was also capable of outputting gibberish. In its announcement, OpenAI stated ‘Due to our concerns about malicious applications of the technology, we are not releasing the trained model’ Footnote i . This immediately drew criticism from many who saw the claim that the technology was so dangerous that it had to be locked up as simply a means of generating hype and media interest. I have no idea whether that figured into OpenAI’s strategy, although subsequent interviews given by Sam Altman, OpenAI’s CEO, suggest that the company was and is pretty serious about the responsible release of the technology it develops. In any case, the full 1.5B parameter model was eventually released in November 2019, following intermediate releases embodying increasingly larger language models: a ‘small’ 124M parameter model in February, a medium 355M model in May, and a 774M model in August. Presaging the attention that GPT-3 would later generate, and no doubt alerted by the suggestion that the technology was dangerous, a number of mainstream media outlets picked up on the story, demonstrating the technology by allowing it to be a co-contributor. The New Yorker ’s John Seabrook discussed predictive-text technology more generally in an interactive piece that, at various points in the article, lets you view GPT-2’s contributions based on the preceding human-authored content; Footnote j and The Economist got GPT-2 to answer a youth essay question on climate change and had a team of judges assess the results. Footnote k 3. GPT-3: A generator to trump all others In June 2020, OpenAI announced GPT-3, a new language model more than 100 times larger than GPT-2, with 175B parameters and 96 layers trained on a corpus of 499B tokens of web content, making it by far the largest language model constructed to date. At the time of writing, the closest contenders are considerably smaller, with Microsoft’s T-NLG and Google’s T5-11B both being less than a tenth of GPT-3’s size. And size, it seems, does matter: as it turned out, the texts created by GPT-3 were much more likely to sound coherent than those of its predecessor. Footnote l Again, the model itself was not made available; instead, access was to be provided via an API, thus giving the model’s creators more control over its use. At the time of writing, a beta version of the API is up and running, but you’ll have to get on the presumably rather long wait-list if you want access. In the interim, some information on future pricing has leaked: Footnote m via a typical SaaS tiered pricing model, there’s a free tier that gets you 100,000 generated tokens, a US$100-per-month tier that gets you 2M tokens, and a US$400-per-month tier that gets you 10M. These prices have been criticised as being on the high side; they’re certainly more than the sub-US$50 per month price-point that’s typical of many other SaaS offerings and steep enough to lock out all but the keenest lone researchers. On the other hand, there are no obvious comparators on the basis of which we might establish what counts as a reasonable price, and arguably it’s actually pretty cheap for access to a language model that is estimated to have a compute cost of US$4.6M per training run – and that’s only a fraction of the overall total development and running costs. Footnote n Meanwhile, back in March 2019, the non-profit OpenAI had restructured as a ‘capped-profit’ company, the stated reason being that this was necessary to be able to raise the kind of capital required to fund the company’s high cost of research and maintain a pace of development competitive with major industry players like Google. Following this change, in July 2019, Microsoft agreed to invest US$1B in OpenAI over the next decade; and just over a year later, in September 2020, Microsoft obtained an exclusive licence to GPT-3. The consequences of this deal are unclear, but it’s likely that the API access will be unaffected, whereas Microsoft’s customers might eventually see the benefits of GPT-3 in a range of applications effectively for free. As we noted in the introduction, the predominant sentiment in the media coverage of GPT-3 that has appeared subsequent to its release has been one of awe, sometimes followed by an expression of concern for the future of humanity now that AGI appeared to be in sight, eventually resolving to a recognition that we’re still a long way from Skynet. There’s been a lot of praise for the technology’s capabilities, especially in text generation. The typical use of the API involves providing a prompt and some initial text to get the model going, along with some optional parameter fiddling. Some of the outputs produced are truly breathtaking in their plausibility and believability as candidates for being human-authored text. The key word in that previous sentence, though, is ‘some’; we’ll get back to that below. There’s insufficient space to include examples here, but you’ve probably seen some already, and if not, you can easily find them all over the web via your favourite search engine. Footnote o Apart from the obvious application of text generation, the technology has also been lauded for its results in a wide range of other areas, some quite surprising: so you’ll easily find examples and discussion of the model’s capability in generating poetry, playing chess, doing arithmetic and writing web interface code on the basis of requirements expressed in natural language. It really is hard not to be impressed. But, as noted above, there is a ‘but’. 4. Can you trust a transformer? As has been widely noted, the technology has its limitations. The following have been identified by many observers: • Its outputs may lack semantic coherence, resulting in text that is gibberish and increasingly nonsensical as the output grows longer. • Its outputs embody all the biases that might be found in its training data: if you want white supremacist manifestos, GPT-3 can be coaxed to produce them endlessly. • Its outputs may correspond to assertions that are not consonant with the truth. As a consequence of these weaknesess, many of the impressive outputs that have been demonstrated are the results of cherry-picking: you run the API with the same prompt a few times, then pick the best result, rejecting those which sound less convincing or are just plain rubbish. The Guardian attracted a lot of flak for being, in the eyes of many commentators, misleading in printing a news story entitled ‘A robot wrote this entire article. Are you scared yet, human?’. Footnote p The newspaper had set GPT-3 an assignment: convince us that robots come in peace. An editorial footnote admits GPT-3 produced eight different outputs, or essays. Each was unique, interesting and advanced a different argument. The Guardian could have just run one of the essays in its entirety. However, we chose instead to pick the best parts of each, in order to capture the different styles and registers of the AI. To anyone who has ever looked at a pile of rejected GPT-3 outputs, this sounds more than just a little disingenuous; and the newspaper’s subsequent claim that ‘editing GPT-3’s op-ed was no different to editing a human op-ed’ might be considered insulting by the newspaper’s human contributors. At the time of writing, The Guardian hadn’t published the full set of outputs, so it’s possible that a few of them are ‘unique’ and ‘interesting’ because they read like acid trip fiction. Incoherent output is certainly a problem. But in terms of the weaknesses identified above, it’s the last of the three that I want to single out as a major concern. Ultimately, there is nothing other than the fortuitous alignment of its textual statistics to make GPT-3 lean towards uttering statements which accord with reality. This is an important characteristic in determining what kinds of applications of the technology are appropriate. In the case of The Guardian ’s playful experiment, there was never any suggestion that GPT-3’s output be taken seriously, or that it should be measured for its truth or falsity. But in those situations where truth is important, then we have a problem. This is most evident when GPT-3 is used as a question-answering system. Yes, it often does provide the correct answer to the question posed; but it often does not, and unless you already know the answer to the question ahead of time, you can’t tell which of the two scenarios you’re faced with. In line with much other reporting, Kelsey Piper in Vox acknowledges the scope for error, saying ‘GPT-3 can even correctly answer medical questions and explain its answers … though you should not trust all its answers’. Footnote q But that sounds like rather flawed logic: if you know you can’t trust some of its answers, then you can’t trust any of them. Of course, these observations are not new. As Gary Marcus and Ernest Davis conclude in their piece in the MIT Technology Review : Footnote r ‘It’s a fluent spouter of bullshit, but even with 175B parameters and 450 gigabytes of input data, it’s not a reliable interpreter of the world’. OpenAI CEO Sam Altman himself underlined the limitations when he tweeted ‘The GPT-3 hype is way too much … it still has serious weaknesses and sometimes makes very silly mistakes.’ Footnote s I’m glad he came out and said this – but to suggest that it ‘makes mistakes’ already assumes some notion of intent, which GPT-3 lacks. 5. Unreliable doesn’t mean useless The bottom line is that GPT-3 is, to borrow a term from literary criticism, an ‘unreliable narrator’: its credibility, at least in regard to some key application use cases, is compromised by the fact that it is untethered to the truth. This is not to say that GPT-3 is devoid of practical application; far from it. But it means that some use cases are appropriate and some are not. The production of creative fiction, provided it is clearly identified as such, is of course perfectly fine; likewise poetry. And I’m sure we’ll see many fantasy games where GPT-3 authors machine contributions to dialogues. But, as already hinted, it seems to me that question-answering or advice-giving systems, where it’s important that the resulting answer be true, are a risk too far. I expect that OpenAI’s vetting process for requests for API access will rule out applications that attempt to offer advice in critical areas like health, but the demarcation lines here are fuzzy. For example, FitnessAI Footnote t , which uses GPT-3 to answer questions about fitness, is already up and running. Now, I’m sure this application uses all kinds of pre- and post-filtering to avoid dealing with questions whose answers carry health risk, but it’s hard to see how we can ensure that it won’t at some point provide misinformation that leads to injury. On the other hand, applications where a human stays in the loop are much safer, and we’re already seeing a slew of these. Almost all of these are effectively augmented writing tools that take a user’s textual input and provide an alternative version of that input, either longer or shorter depending on the application in question. OtherSideAI’s Quick Response Footnote u generates full-length emails in your style of writing given an outline of the key points you want covered; at the time of writing, the company had just raised US$2.6M in a seed funding round. Compose.ai Footnote v and Magic Email Footnote w also offer email-writing applications; and in a similar vein, Kriya.ai Footnote x generates personalised introduction requests: just what you need if you’re trying to build up your LinkedIn network—you get 200 intros for US$9. Dover.ai Footnote y rewrites your short job description into a longer variant. Copy.ai Footnote z writes ad copy given a product description; you can sign up for a free trial. Taglines Footnote aa is another copy-writing tool, generating taglines based on product or service descriptions. It’s crucial to the success of these applications that in each case you can choose to accept, reject or edit the output generated, so you’re not required to blindly place your trust in what is, ultimately, the wisdom of the web. But things get trickier when you as a user may not be in a position to properly assess the outputs. Machine translation to or from a language you don’t know is an already extant instance of this, and the reason why most of us would be willing to rely on an MT system to give us the gist of a news article but wouldn’t be comfortable relying on it to translate a legally binding contract without some human review. And so I’m more wary of apps like that demonstrated by Michael Tefula, which turns legalese into plain English: Footnote ab this sounds great in principle, but relying on the output would seem to carry a level of risk. Even if used as a writing assistance tool by a lawyer who’s in a position to knowledgably post-edit the results, there’s the risk of learned over-reliance – a danger that, ultimately, none of these applications is immune to. 6. Should we be worried after all? We started out by observing that, despite the teasing of mainstream press headlines to the contrary, GPT-3 doesn’t signal the beginning of the end for humanity. But that doesn’t mean we shouldn’t be concerned about the potential misuses of the technology. Helpfully, something of an ‘ethics in AI’ industry has grown up in the last few years, so it’s unlikely that dubious uses of GPT-3 will avoid scrutiny. And, as we observed earlier, OpenAI itself is concerned about responsible use; here’s a particularly relevant paragraph from their blog: Footnote ac One key factor we consider in approving uses of the API is the extent to which an application exhibits open-ended versus constrained behaviour with regard to the underlying generative capabilities of the system. Open-ended applications of the API (i.e., ones that enable frictionless generation of large amounts of customisable text via arbitrary prompts) are especially susceptible to misuse. Constraints that can make generative use cases safer include systems design that keeps a human in the loop, end user access restrictions, post-processing of outputs, content filtration, input/output length limitations, active monitoring and topicality limitations. This, of course, is to be applauded, although it remains to be seen how workable these processes will be as the number of applications of the technology ramps up, and the ethical issues around specific cases get muddier; there are likely to be echoes here of the kinds of content moderation dilemmas faced by Facebook and Twitter. I understand why OpenAI’s characterisation of what is safe, and what is not, has to be couched in pretty general terms, but it seems to me that they could go further. From where I sit, one maxim is incontrovertible: To the extent that a use case places importance on the truth of the outputs provided, it is not a good fit for GPT-3. But that might not go down well with Marketing. References a a https://www.zdnet.com/article/openais-gigantic-gpt-3-hints-at-the-limits-of-language-models-for-ai/ b b https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/ c c https://www.wired.com/story/ai-text-generator-gpt-3-learning-language-fitfully/ d d https://www.theverge.com/21346343/gpt-3-explainer-openai-examples-errors-agi-potential e e https://www.bbc.com/news/technology-53530454 f f https://www.nytimes.com/2020/07/29/opinion/gpt-3-ai-automation.html g g https://www.economist.com/science-and-technology/2020/08/06/a-new-ai-language-model-generates-poetry-and-prose h h https://www.telegraph.co.uk/technology/2020/08/26/forget-deepfakes-ai-generated-text-should-worried/ i i https://openai.com/blog/better-language-models/ j j https://www.newyorker.com/magazine/2019/10/14/can-a-machine-learn-to-write-for-the-new-yorker k k https://www.economist.com/open-future/2019/10/01/how-to-respond-to-climate-change-if-you-are-an-algorithm l l Gwern Branwen suggests that, for fiction generation, the number of samples he’d need to consider before finding one worth showing off has fallen from 100 in the case of GPT-2 to five in the case of GPT-3: on that metric, at least, GPT-3 is 20 times better. This does, however, appear to require careful prompt refinement. See https://www.gwern.net/GPT-3. m m https://bdtechtalks.com/2020/09/21/gpt-3-economy-business-model/ n n https://lambdalabs.com/blog/demystifying-gpt-3/ o o A comprehensive set of examples is provided on Gwern Branwen’s website, along with extensive and detailed technical discussion: see https://www.gwern.net/GPT-3. p p https://www.theguardian.com/commentisfree/2020/sep/08/robot-wrote-this-article-gpt-3 q q https://www.vox.com/future-perfect/21355768/gpt-3-ai-openai-turing-test-language r r https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/ s s https://twitter.com/sama/status/1284922296348454913 t t https://app.fitnessai.com/knowledge/ u u https://www.othersideai.com/ ; video at https://twitter.com/i/status/1285776335638614017 . v v https://compose.ai/ w w https://magicemail.io/ x x https://www.kriya.ai/ y y https://www.dover.io/tools/job-description-rewriter ; This didn’t appear to be working when I tried it. z z https://www.copy.ai/ aa aa https://www.taglines.ai/ ab ab See the video at https://twitter.com/i/status/1287425989878915074 . ac ac https://openai.com/blog/openai-api/ You have Access Open access 284 Cited by Cited by Loading... Cited by 284 Crossref Citations This article has been cited by the following publications. This list is generated based on data provided by Crossref . Orozco-del-Castillo, Mauricio Gabriel                                                                          Orozco-del-Castillo, Esperanza Carolina                                                                          Brito-Borges, Esteban                                                                          Bermejo-Sabbagh, Carlos                                      and                                      Cuevas-Cuevas, Nora                                   2021. Telematics and Computing .                                                                                                                                            Vol. 1430,                                    Issue. ,                                                                       p.                                      1. CrossRef Google Scholar Fantozzi, Paolo                                                                          Laura, Luigi                                                                          Nuzzo, Antonio                                                                          Piselli, Riccardo                                                                          Di Marzo-Serugendo, G.                                                                          Drăgoicea, M.                                      and                                      Ralyté, J.                                   2021. Justice as a Service .                                                                                                         ITM Web of Conferences,                                    Vol. 38,                                    Issue. ,                                                                       p.                                      02007. CrossRef Google Scholar Yetis, Hasan                                      and                                      Karakose, Mehmet                                   2021. Binary Pooling Circuits for Quantum Computing .                                                                                                                                                                                                                                                     p.                                      161. CrossRef Google Scholar Ramackers, Guus J.                                                                          Griffioen, Pepijn P.                                                                          Schouten, Martijn B.J.                                      and                                      Chaudron, Michel R.V.                                   2021. From Prose to Prototype: Synthesising Executable UML Models from Natural Language .                                                                                                                                                                                                                                                     p.                                      380. CrossRef Google Scholar Palasundram, Kulothunkan                                                                          Mohd Sharef, Nurfadhlina                                                                          Kasmiran, Khairul Azhar                                      and                                      Azman, Azreen                                   2021. SEQ2SEQ++: A Multitasking-Based Seq2seq Model to Generate Meaningful and Relevant Answers .                                                                                                         IEEE Access,                                    Vol. 9,                                    Issue. ,                                                                       p.                                      164949. CrossRef Google Scholar Church, Kenneth Ward                                                                          Chen, Zeyu                                      and                                      Ma, Yanjun                                   2021. Emerging trends: A gentle introduction to fine-tuning .                                                                                                         Natural Language Engineering,                                    Vol. 27,                                    Issue. 6,                                                                       p.                                      763. CrossRef Google Scholar Nagle-McNaughton, Timothy Paul                                                                          Scuderi, Louis Anthony                                      and                                      Erickson, Nicholas                                   2022. Squeezing Data from a Rock: Machine Learning for Martian Science .                                                                                                         Geosciences,                                    Vol. 12,                                    Issue. 6,                                                                       p.                                      248. CrossRef Google Scholar Farimani, Saeede Anbaee                                                                          Jahan, Majid Vafaei                                      and                                      Milani Fard, Amin                                   2022. From Text Representation to Financial Market Prediction: A Literature Review .                                                                                                         Information,                                    Vol. 13,                                    Issue. 10,                                                                       p.                                      466. CrossRef Google Scholar Xiang, Zheng                                                                          Liu, Xiaoming                                                                          Yang, Guan                                      and                                      Liu, Yang                                   2022. Topic Embedded Representation Enhanced Variational Wasserstein Autoencoder for Text Modeling .                                                                                                                                                                                                                                                     p.                                      1318. CrossRef Google Scholar 2022. CrossRef Ward Church, Kenneth                                                                          Cai, Xingyu                                                                          Ying, Yibiao                                                                          Chen, Zeyu                                                                          Xun, Guangxu                                      and                                      Bian, Yuchen                                   2022. Emerging trends: General fine-tuning (gft) .                                                                                                         Natural Language Engineering,                                    Vol. 28,                                    Issue. 4,                                                                       p.                                      519. CrossRef Google Scholar Landro, Nicola                                                                          Gallo, Ignazio                                                                          La Grassa, Riccardo                                      and                                      Federici, Edoardo                                   2022. Two New Datasets for Italian-Language Abstractive Text Summarization .                                                                                                         Information,                                    Vol. 13,                                    Issue. 5,                                                                       p.                                      228. CrossRef Google Scholar Gatto, Luigi                                                                          Fulvio Gaglio, Giuseppe                                                                          Augello, Agnese                                                                          Caggianese, Giuseppe                                                                          Gallo, Luigi                                      and                                      La Cascia, Marco                                   2022. MET-iquette: enabling virtual agents to have a social compliant behavior in the Metaverse .                                                                                                                                                                                                                                                     p.                                      394. CrossRef Google Scholar Álvarez-Carmona, Miguel Á.                                                                          Aranda, Ramón                                                                          Rodríguez-Gonzalez, Ansel Y.                                                                          Fajardo-Delgado, Daniel                                                                          Sánchez, María Guadalupe                                                                          Pérez-Espinosa, Humberto                                                                          Martínez-Miranda, Juan                                                                          Guerrero-Rodríguez, Rafael                                                                          Bustio-Martínez, Lázaro                                      and                                      Díaz-Pacheco, Ángel                                   2022. Natural language processing applied to tourism research: A systematic review and future research directions .                                                                                                         Journal of King Saud University - Computer and Information Sciences,                                    Vol. 34,                                    Issue. 10,                                                                       p.                                      10125. CrossRef Google Scholar Dale, Robert                                   2022. $NLP: How to spend a billion dollars .                                                                                                         Natural Language Engineering,                                    Vol. 28,                                    Issue. 1,                                                                       p.                                      125. CrossRef Google Scholar Church, Kenneth Ward                                   2022. Emerging trends: Deep nets thrive on scale .                                                                                                         Natural Language Engineering,                                    Vol. 28,                                    Issue. 5,                                                                       p.                                      673. CrossRef Google Scholar Moran, Rachel E.                                      and                                      Shaikh, Sonia Jawaid                                   2022. Robots in the News and Newsrooms: Unpacking Meta-Journalistic Discourse on the Use of Artificial Intelligence in Journalism .                                                                                                         Digital Journalism,                                    Vol. 10,                                    Issue. 10,                                                                       p.                                      1756. CrossRef Google Scholar Zhang, Yan                                                                          Zhang, Fan                                      and                                      Chen, Nengcheng                                   2022. Migratable urban street scene sensing method based on vision language pre-trained model .                                                                                                         International Journal of Applied Earth Observation and Geoinformation,                                    Vol. 113,                                    Issue. ,                                                                       p.                                      102989. CrossRef Google Scholar Aylett, Ruth                                   2022. The Handbook on Socially Interactive Agents . CrossRef Google Scholar Fatima, Noureen                                                                          Imran, Ali Shariq                                                                          Kastrati, Zenun                                                                          Daudpota, Sher Muhammad                                      and                                      Soomro, Abdullah                                   2022. A Systematic Literature Review on Text Generation Using Deep Neural Network Models .                                                                                                         IEEE Access,                                    Vol. 10,                                    Issue. ,                                                                       p.                                      53490. CrossRef Google Scholar Download full list Google Scholar Citations View all Google Scholar citations for this article. × Our Site Accessibility Contact & Help Legal Notices Our Platforms Cambridge Core Cambridge Open Engage Cambridge Higher Education Our Products Journals Books Elements Textbooks Courseware Join us online Location Please choose a valid location. Update Legal Information Rights & Permissions Copyright Privacy Notice Terms of Use Cookies Policy Cambridge University Press 2025 Cancel Confirm × Save article to Kindle To send this article to your Kindle, first ensure no-reply@cambridge.org is added to your Approved Personal Document E-mail List under your Personal Document Settings on the Manage Your Content and Devices page of your Amazon account. Then enter the ‘name’ part of your Kindle email address below. Find out more about sending to your Kindle. Find out more about saving to your Kindle . Note you can select to save to either the @free.kindle.com or @kindle.com variations. ‘@free.kindle.com’ emails are free but can only be saved to your device when it is connected to wi-fi. ‘@kindle.com’ emails can be delivered even when you are not connected to wi-fi, but note that service fees apply. Find out more about the Kindle Personal Document Service. GPT-3: What’s it good for? Volume 27, Issue 1 Robert Dale (a1) DOI: https://doi.org/10.1017/S1351324920000601 Your Kindle email address Please provide your Kindle email. @free.kindle.com @kindle.com ( service fees apply ) Available formats PDF Please select a format to save. By using this service, you agree that you will only keep content for personal use, and will not openly distribute them via Dropbox, Google Drive or other file sharing services Please confirm that you accept the terms of use. Cancel Save × Save article to Dropbox To save this article to your Dropbox account, please select one or more formats and confirm that you agree to abide by our usage policies. If this is the first time you used this feature, you will be asked to authorise Cambridge Core to connect with your Dropbox account. Find out more about saving content to Dropbox . GPT-3: What’s it good for? Volume 27, Issue 1 Robert Dale (a1) DOI: https://doi.org/10.1017/S1351324920000601 Available formats PDF Please select a format to save. By using this service, you agree that you will only keep content for personal use, and will not openly distribute them via Dropbox, Google Drive or other file sharing services Please confirm that you accept the terms of use. Cancel Save × Save article to Google Drive To save this article to your Google Drive account, please select one or more formats and confirm that you agree to abide by our usage policies. If this is the first time you used this feature, you will be asked to authorise Cambridge Core to connect with your Google Drive account. Find out more about saving content to Google Drive . GPT-3: What’s it good for? Volume 27, Issue 1 Robert Dale (a1) DOI: https://doi.org/10.1017/S1351324920000601 Available formats PDF Please select a format to save. By using this service, you agree that you will only keep content for personal use, and will not openly distribute them via Dropbox, Google Drive or other file sharing services Please confirm that you accept the terms of use. Cancel Save × × Reply to: Submit a response Title * Please enter a title for your response. Contents * Contents help Close Contents help - No HTML tags allowed - Web page URLs will display as text only - Lines and paragraphs break automatically - Attachments, images or tables are not permitted Please enter your response. Your details First name * Please enter your first name. Last name * Please enter your last name. Email * Email help Close Email help Your email address will be used in order to notify you when your comment has been reviewed by the moderator and in case the author(s) of the article or the moderator need to contact you directly. Please enter a valid email address. Occupation Please enter your occupation. Affiliation Please enter any affiliation. You have entered the maximum number of contributors Conflicting interests Do you have any conflicting interests? * Conflicting interests help Close Conflicting interests help Please list any fees and grants from, employment by, consultancy for, shared ownership in or any close relationship with, at any time over the preceding 36 months, any organisation whose interests may be affected by the publication of the response. Please also list any non-financial associations or interests (personal, professional, political, institutional, religious or other) that a reasonable reader would want to know about in relation to the submitted work. This pertains to all the authors of the piece, their spouses or partners. Yes No More information * Please enter details of the conflict of interest or select 'No'. Please tick the box to confirm you agree to our Terms of use . * Please accept terms of use. Please tick the box to confirm you agree that your name, comment and conflicts of interest (if accepted) will be visible on the website and your comment may be printed in the journal at the Editor’s discretion. * Please confirm you agree that your details will be displayed.